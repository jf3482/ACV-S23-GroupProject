{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-5MojmoX8RA"
   },
   "source": [
    "# Computing quantitative features for all data.\n",
    "1) Linking to drive\n",
    "\n",
    "2) Initialization\n",
    "\n",
    "3) Computing results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7XTYtuc3c4xm"
   },
   "source": [
    "## Import and linking to drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "qxSbu0ZM_UVy"
   },
   "outputs": [],
   "source": [
    "## Run once to link to google drive using GCP\n",
    "#!sudo apt-get install google-drive-ocamlfuse\n",
    "#!sudo add-apt-repository ppa:alessandro-strada/ppa\n",
    "#!sudo apt-get update\n",
    "#!sudo apt-get install google-drive-ocamlfuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "i1wkc3aK_UYW"
   },
   "outputs": [],
   "source": [
    "#!google-drive-ocamlfuse -headless -id=553698332080-4ilebkr6tajj9d4on76a6sfjilo8dbob.apps.googleusercontent.com -secret=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"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "md6RQH9CA-_0"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zYfVALPZlXsY",
    "outputId": "895dd5c2-c282-46ee-8df5-20006b61ee93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lpips in c:\\users\\athrun\\anaconda3\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: torch>=0.4.0 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from lpips) (1.12.1)\n",
      "Requirement already satisfied: tqdm>=4.28.1 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from lpips) (4.64.1)\n",
      "Requirement already satisfied: scipy>=1.0.1 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from lpips) (1.9.3)\n",
      "Requirement already satisfied: numpy>=1.14.3 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from lpips) (1.23.5)\n",
      "Requirement already satisfied: torchvision>=0.2.1 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from lpips) (0.13.1)\n",
      "Requirement already satisfied: typing_extensions in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from torch>=0.4.0->lpips) (4.3.0)\n",
      "Requirement already satisfied: requests in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from torchvision>=0.2.1->lpips) (2.28.1)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from torchvision>=0.2.1->lpips) (9.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from tqdm>=4.28.1->lpips) (0.4.5)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.2.1->lpips) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.2.1->lpips) (1.26.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.2.1->lpips) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\athrun\\anaconda3\\lib\\site-packages (from requests->torchvision>=0.2.1->lpips) (2022.12.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install lpips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z3xMOa7lA-K1"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "\n",
    "import lpips\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity as ssim\n",
    "import torch\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R-8IxC5y__oe"
   },
   "source": [
    "# Linking up drive and initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Z1tr_V4_Uaj"
   },
   "source": [
    "#Initializing google drive to a folder\n",
    "if not os.path.exists(\"./acv\"):\n",
    "  os.makedirs(\"./acv\")\n",
    "\n",
    "!google-drive-ocamlfuse acv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ENlB1LFr_UdO"
   },
   "outputs": [],
   "source": [
    "os.chdir('G:\\ACVProjects\\Group-revised\\Codebase\\AID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "id": "6CMbCVf9hYbu",
    "outputId": "a6cc427b-f067-46b5-c61e-9c0e25cebd46"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfrom google.colab import drive\\n\\ndrive.mount('/content/gdrive')\\n\\nos.chdir('/content/gdrive/MyDrive/Courses/COMS 4995-6 - Applied Computer Vision/Group Project/Codebase/AID') \\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "os.chdir('/content/gdrive/MyDrive/Courses/COMS 4995-6 - Applied Computer Vision/Group Project/Codebase/AID') \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCK6fLjBVnKH"
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "W-dbFRP_VFlO"
   },
   "outputs": [],
   "source": [
    "dir_hr = '../../Data/AID/AIDx1/'\n",
    "dir_lr = ['../../Data/AID/AIDx8/','../../Data/AID/AIDx4/','../../Data/AID/AIDx8/','../../Data/AID/AIDx4/']\n",
    "dir_out = '../../Data/AID/Outputs2/'\n",
    "scale = [8,4,8,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_case = ['EDSRp4_eval8xto1x','EDSRp4b_eval4xto1x','EDSRp8x-Bicubic_X8_L1loss_lr1e4_04182023','EDSRp4x-Bicubic_X4_L1loss_lr1e4_04172023']\n",
    "str_case2 = ['8xto1xs','4xto1xs','8xto1x','4xto1x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "4rVgrvBYKYtZ"
   },
   "outputs": [],
   "source": [
    "csv_train = '../../Data/AID/Train1_5class/train_HR.csv'\n",
    "csv_valid = '../../Data/AID/Train1_5class/valid_HR.csv'\n",
    "csv_test = '../../Data/AID/Test1_2class/test_HR.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0tZmY0DKY_kj"
   },
   "source": [
    "## Compute quantitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\Athrun\\anaconda3\\lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/710 [00:00<?, ?it/s]C:\\Users\\Athrun\\AppData\\Local\\Temp\\ipykernel_20960\\410159584.py:39: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ssim_value = ssim(img1_np, img2_np, multichannel=True)\n",
      "C:\\Users\\Athrun\\AppData\\Local\\Temp\\ipykernel_20960\\410159584.py:40: FutureWarning: `multichannel` is a deprecated argument name for `structural_similarity`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
      "  ssim_value2 = ssim(img1_np, img3_np, multichannel=True)\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 710/710 [1:04:45<00:00,  5.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n",
      "Loading model from: C:\\Users\\Athrun\\anaconda3\\lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████████████████████████████████████████████████████▋                        | 494/710 [44:41<19:17,  5.36s/it]"
     ]
    }
   ],
   "source": [
    "for str_test in ['test','valid']:\n",
    "    csv_file = eval('csv_' + str_test)\n",
    "    list_files = np.genfromtxt(csv_file,dtype='str')\n",
    "    for i,case in enumerate(str_case):\n",
    "        # Set up the paths to the dataset directory and the output file\n",
    "        dir_res = dir_out \n",
    "        output_file = dir_res + str_case2[i] + '_' + str_test + '_result.csv'\n",
    "\n",
    "        # Initialize the LPIPS loss function\n",
    "        loss_fn_vgg = lpips.LPIPS(net='vgg')\n",
    "\n",
    "        # Iterate over all image pairs in the dataset directory and compute LPIPS, PSNR, and SSIM for each pair\n",
    "        with open(output_file, 'w') as f:\n",
    "            for file in tqdm(list_files):\n",
    "              ind = [m.start() for m in list(re.finditer(r'/',file))]\n",
    "\n",
    "              img_HR = Image.open(file)\n",
    "              img_LR = Image.open(dir_lr[i] + file[ind[-2]+1:]).resize((600,600))\n",
    "              file2 = dir_res + str_case[i] + '/2xto1x_' + str_test + file[ind[-1]:]\n",
    "              img_SR = Image.open(file2)\n",
    "\n",
    "              # Convert images to tensors\n",
    "              img1_tensor = torch.tensor(np.array(img_HR)).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "              img2_tensor = torch.tensor(np.array(img_SR)).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "              img3_tensor = torch.tensor(np.array(img_LR)).permute(2, 0, 1).unsqueeze(0).float() / 255.0\n",
    "\n",
    "              # Compute LPIPS distance\n",
    "              lpips_distance = loss_fn_vgg(img1_tensor, img2_tensor).item()\n",
    "              lpips_distance2 = loss_fn_vgg(img1_tensor, img3_tensor).item()\n",
    "\n",
    "              # Compute PSNR\n",
    "              img1_np = np.array(img_HR)\n",
    "              img2_np = np.array(img_SR)\n",
    "              img3_np = np.array(img_LR)\n",
    "              psnr = peak_signal_noise_ratio(img1_np, img2_np)\n",
    "              psnr2 = peak_signal_noise_ratio(img1_np, img3_np)\n",
    "\n",
    "              # Compute SSIM\n",
    "              ssim_value = ssim(img1_np, img2_np, multichannel=True)\n",
    "              ssim_value2 = ssim(img1_np, img3_np, multichannel=True)\n",
    "\n",
    "              # Write the results to the output file\n",
    "              f.write(f\"{file},{file2},{lpips_distance},{psnr},{ssim_value},{lpips_distance2},{psnr2},{ssim_value2}\\n\")\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
